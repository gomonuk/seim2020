\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{substitutefont}
\usepackage{multicol,tabularx}

\addto\captionsrussian{
    \renewcommand{\IEEEkeywordsname}{Ключевые понятия}
}

\substitutefont{T2A}{\familydefault}{Tempora-TLF}
\makeatletter
\input{t2atempora-tlf.fd}
\DeclareFontShape{T2A}{Tempora-TLF}{m}{sc}{<-> ssub * Tempora-TLF/m/n}{}
\makeatother

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.8em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

    \title{Интеграционный подход распознавания зашумленной русскоязычной речи}

% \author{
% \IEEEauthorblockN{Даниил Гомонюк}
% \IEEEauthorblockA{\textit{Высшая школа программной инженерии} \\
% \textit{Санкт-Петербургский Политехнический Университет}\\
% Санкт-Петербург, Россия \\
% dan.gomonuk@gmail.com}
% \and
% \IEEEauthorblockN{Игорь Никифоров}
% \IEEEauthorblockA{
% \textit{Высшая школа программной инженерии} \\
%  \textit{Санкт-Петербургский Политехнический Университет}\\
%  Санкт-Петербург, Россия \\
% igor.nikiforovv@gmail.com}
% \\
% \IEEEauthorblockN{Дмитрий Дробинцев}
% \IEEEauthorblockA{\textit{Высшая школа программной инженерии} \\
% \textit{Санкт-Петербургский Политехнический Университет}\\
% Санкт-Петербург, Россия \\
% drobintsev\_df@spbstu.ru}
% }

    \author{\IEEEauthorblockN{
        Даниил Гомонюк\IEEEauthorrefmark{1},
        Игорь Никифоров\IEEEauthorrefmark{2},
        Дмитрий Дробинцев\IEEEauthorrefmark{3}}
        \IEEEauthorblockA{
            \textit{Высшая школа программной инженерии} \\
            \textit{Санкт-Петербургский Политехнический Университет}\\
            Санкт-Петербург, Россия \\
            Email:
            \IEEEauthorrefmark{1}dan.gomonuk@gmail.com,
            \IEEEauthorrefmark{2}igor.nikiforovv@gmail.com,
            \IEEEauthorrefmark{3}drobintsev\_df@spbstu.ru
        }}

    \maketitle

    \begin{abstract}
        Исследовательская работа посвящена методам автоматического преобразования аудиозаписей в текстовый формат, другими словами, распознаванию речи.

        В частности, особое внимание уделено распознаванию зашумленной русской речи.

        В работе предоставления обзор существующих методов распознавания, которые включают "конечные" и "гибридные" методы. Приведен сравнительный обзор существующих реализаций рассмотренных методов и их метрики. На основе сравнительного анализа делается вывод, что технология "Mozilla DeepSpeech" наиболее мощный инструмент распознавания.

        Отличительно особенностью работы является использование комбинированного метода распознавания, который позволяет улучшить качество распознавания зашумленной речи. Комбинированный метод объединяет в себе "конечные" и "гибридные" методы. Предлагаемый подход реализован в программном средстве для распознавания зашумленной русской речи с использованием технологии "Mozilla DeepSpeech". Результаты показывают эффективность предложенного подхода.

        Разработанное программное средство может быть использовано компаниям в целях снижения трудозатрат при осуществлении технической поддержки для заказчиков.
    \end{abstract}

    \begin{IEEEkeywords}
        распознавание речи, зашумленная речь, аудиозапись, Mozilla DeepSpeech, Baidu, Kaldi
    \end{IEEEkeywords}

    \section{Введение}

    Инновационные подходы и технологии с каждым днем все больше и больше интегрируются в устоявшихся годами сферах жизнедеятельности человека.
    Не исключением является и применение методов машинного обучения для распознавания аудиозаписей.
    Так, например, распознавание речи по аудиозаписям позволяет повысить эффективность служб клиентской поддержки, даёт возможность проводить аналитику звонков [1], избегая проблем с соблюдением закона “О персональных данных”, так как зачастую в аудио-звонках упоминается конфиденциальная информация [2].
    Ниже перечислены две основнные группы методов: основанные на применении скрытых марковских моделей и методы снованные на нейронных сетях.

    Методы, основанные на применении скрытых марковских моделей [3].
    Инструменты на основе этих методов очень точны, но требуют составления словаря, соотносящего слово и его фонемы (например слово “ноль” разбивается на фонемы “n” “oo” “ll”).
    Такая система не сможет распознать слово которого нет в словаре, но чем больше словарь, тем больше вероятность ошибки.
    Такие инструменты идеально подходят для распознавания заранее известных фраз, например речевых команд, но они не столь эффективны при распознавании спонтанной речи.
    Одной из таких систем является CMUSphinx;

    Методы, основанные на нейронных сетях, можно разделить на “интегральные” и "гибридные"[4] методы.
    Несмотря на то, что они подходят для распознавания спонтанной речи, они не избавлены от недостатков:

    \begin{itemize}
        \itemкачество распознавания во многом зависит от качества исходной аудиозаписи, что влечет собой накладывание высоких требований на качество изначальной аудиозаписи;
        \itemотсутствие универсальности методов и библиотек, реализующих методы.
        Зачастую под задачу приходится создавать свое собственное решение.
        \itemдля каждого языка (русский, английский, китайский), приходится проводить дополнительную настройку систем распознавания.
    \end{itemize}
    Поэтому актуальной является задача создания такого метода, который бы позволял снизить влияние перечисленных недостатков и повысить эффективность распознавания речи.
    Важно отметить еще и то, что на текущий день существует малое количество работ, специализирующихся на распознавании именно русской речи.
    Именно поэтому в работе делается акцент создание комбинированного метода распознавания зашумленной русской речи.

    \begin{table*}[htp]
        \caption{Сравнение различных моделей распознавания речи}
        \begin{center}
            \begin{tabular}{|c|c|c|c|}
                \hline
                Модель & Технология & Речевой корпус & WER \% \\
                \hline
                \multicolumn{4}{|c|}{\textbf{Гибридные СММ/ИНС модели}} \\
                \hline
                CNN & Torch7 & WSJ (Nov’92) & 6.7 \\
                \hline
                Kaldi-dnn5b-pretrain-dbn-dnn-smbr recipe & Kaldi & WSJ (Nov’92) & 3.35 \\
                \hline
                \multicolumn{4}{|c|}{\textbf{CTC модели}} \\
                \hline
                RNN-CTC + Kaldi + trigram LM & Kaldi & WSJ (Nov’92) & 6.7 \\
                \hline
                LSTM-CTC + trigram LM & Eesen & WSJ (Nov’92) & 7.9 \\
                \hline
                \multicolumn{4}{|c|}{\textbf{Шифратор-дешифратор модели}} \\
                \hline
                CNN + RNN + CTC & Baidu & WSJ (Nov’92) & 4.42 \\
                \hline
                CNN + ASG & Torch7,Baidu & LibriSpeech & 7.2 \\
                \hline
            \end{tabular}
            \label{tab1}
        \end{center}
    \end{table*}


    \section{Технологии распознавания речи основанные на нейронных сетях}
    Существует большое количество инструментов и технологий распознавания речи, основанные на нейронных сетях, ведущие открытые решения это Mozilla DeepSpeech и Kaldi. Все методы делятся на две группы: интегральные и гибридные.
    Гибридные решения состоят из множества отдельных компонентов, ошибка в одном компоненте может привести к проблемам в других и повилять на общий результат. Гибридные решения сложнее в создании, чем решения, основанные на интегральном подходе, каждый компонент системы необходимо подбирать и настраивать под конкретную задачу.
    Интегральный метод заключается в попытке создать одну нейронную сеть, которая не нуждается в других компонентах, к примеру таких как акустическая или языковая модели. К сожалению, для успешного обучения такой модели необходимы тысячи часов аудиозаписей.


    \section{Сравнительный анализ существующих реализаций ASR систем}

    \subsection{Метрики оценки систем автоматизированного распознавания речи}\label{AA}

    Корректная оценка результатов работы ASR, и как следствие возможность корректно сравнить разные ASR, имеет большое значение как для конечных пользователей, так и для разработчиков таких систем. В данной работе представленные метрики будут использоваться не только для сравнения систем, но и для оценки конечного результата работы предложенного метода.
    Для ASR существует две основные группы метрик оценивания [5]:
    \begin{itemize}
        \itemметрики точности распознавания;
        \itemметрики скорости распознавания;
    \end{itemize}

    Основным способом оценки точности распознавания являются метрики, основанные на расстоянии Левенштейна [6]. 
Расстояние Левенштейна — это метрика, определяющая разницу между двумя символьными последовательностями. Она рассчитывается как количество операций удаления, вставки и замены преобразовывающих одну последовательность символов в другую. Наиболее распространенными метриками, основанными на расстоянии Левенштейна, являются WER - количество ошибочных слов в предложении и SER количество ошибочных предложений.

Важным фактором работы любой системы является скорость, с которой она отдает результат. Для ASR такой метрикой, показывающей скорость работы, является SF(RT). Она считается как отношение скорости обработки аудиофайла к длительности этого аудиофайла. К примеру, если файл длительность в одну минуту обрабатывается тридцать секунд, то SF = 0.5.

Естественным условием для сравнения разных ASR с помощью этой метрики является запуск тестов на одинаковом оборудовании

\subsection{Сравнительный анализ ASR по метрике WER}\label{AA}
Проведём сравнительный анализ различных моделей для распознавания речи, по трём основным группам: гибридные СММ/ИНС модели, CTC-модели, модели, на основе механизма внимания. Возьмём только две лучше модели в каждой группе по показателю WER.

Как можно увидеть из Таблицы 1. однозначными лидерами по показателю WER являются технологии Kaldi и Baidu. Далее мы будем использовать их реализации: vosk - реализацию Kaldi для русского языка и DeepSpeech - открытый проект компании Mozilla реализующий технологию Baidu.

Даже на этой небольшой выборке видно насколько обширно количество способов настройки моделей машинного обучения, и на сколько сильно отличаются показатели качества даже в рамках одной технологии. Кроме того, ни одна из этих систем не проводят анализ распознанного текста, так как единицей их работы являются морфемы - т.е. звуки. Предложенный интеграционный метод, предполагает получение результатов от нескольких разных ASR, и проводит коррекцию ошибок основываясь на результатах других ASR, подбирает наиболее вероятные слова там, где распознание не удалось. Выбор из полученных вариантов может произвести оператор-человек или система контекстного анализа.

Другими словами, предлагается сделать ансамбль ASR систем с коррекцией ошибок.

\section{Интеграционный подход распознавания зашумленной речи}
\subsection{Описание метода}
Суть предложенного подхода заключается в том, что аудиозапись, предварительно очищенная от шумов, распознаются с помощью нескольких разных систем автоматического распознавания речи (далее ASR). Полученные результаты составят список наиболее вероятных гипотез(N-Best-List), выбор из которых может произвести либо оператор-человек, либо система контекстного анализа.

Суть интегрального метода заключается в попытке получить из аудиозаписи текст на основе семантики конкретного языка и звучании букв, из-за сложности и большого количества факторов, влияющих на успех, необходимы тысячи часов аудиозаписей.

\begin{figure}[h]
\centering
\includegraphics[width=0.4\textwidth]{./Diagram1.jpg}
\caption{Cтруктурная схема предлагаемого подхода}
\label{fig:Panel}
\end{figure}

На вход программной системы передается аудиозапись, после прохождения нескольких этапов на выходе пользователь системы получает наиболее вероятное предложение.

Первый этап, предобработка аудио. Аудиозапись приводится к заданному формату с конкретной частотой дискретизации. Затем производится очистка от шумов, например с помощью БПФ. Очищенная от шумов аудиозапись разбивается на более мелкие по паузам, тем самым мы решаем несколько проблем: во-первых, мы заранее знаем где были паузы - т.е. законченные мысли и можем это использовать при выдаче конечного результата, во-вторых, мы частично избежим проблемы смешения дикторов.

Второй этап, распознование аудио. Полученные аудиозаписи помещаются в базу данных и маркируются как относящиеся к одному тексту. Каждая аудиозапись отправляется параллельно во все системы ASR, на выходе которых мы получаем варианты распознанной фразы. После обработки всех аудиозаписей и получения наборов распознанных фраз можно приступать к анализу текстов.

Третий этап, коррекция ошибок. Сначала мы исправляем ошибки в каждой фразе - сравнивая её с вариантами от других ASR, и составляем наиболее полное предложение. Затем в этом предложении проводится обработка последовательностей, разделенных пробелами - мы определяем является ли последовательность словом, если нет, то какие варианты слов из алфавита могут ей соответствовать. Если последовательность невозможно распознать она маркируется спецсимволом MASK.

Четвертый этап, коррекция ошибок на основе контекста. Полученные фразы проходят ручной или автоматический анализ контекста - составляют ли они осмысленный текст. Автоматический анализ контекста предполагается произвести с помощью BERT.

\subsection{Алгоритм}
Предложенный метод призван уменьшить количество ошибок и как следствие повысить качество распознавания речи. Сделать это предлагается за счет уменьшения пространства всех возможных фраз, путем использования нескольких распознающих систем и получения нескольких возможных вариантов фраз, из которых и будет производится дальнейший выбор.

Полученные фразы должны быть сопоставлены и выявлены наиболее вероятные варианты фраз по следующему алгоритму (описан для трех систем):

Проверяем не состоит ли фраза из одного слова. Удаляем все пробельные символы и определяем является ли получившийся результат словом с заданным редакционным расстоянием. Если да, то обработку можно считать завершенной.

Все три варианта фразы сортируются по следующим параметрам:

\begin{itemize}
\item Совпадения количества пробельных символов у нескольких фраз, это свидетельствует о правильном определении границ слов.
\item Совпадения длинны строки.
\item По количеству точно распознанных слов (сколько слов из фразы есть в словаре)
\item По приоритету ASR, если по какой-то причине мы доверяем одной из ASR больше.
\end{itemize}

После сортировки принимаем первую фразу за истинную. Выравниваем фразы, по совпадающим словам, заменяя пробелы вокруг совпавших слов на спецсимволы. Таким образом мы получаем границы, правильно распознанных участков.

Промежутки, находящиеся внутри спецсимволов, сравниваем по описанному выше алгоритму, не совпавшие промежутки обозначаем как не распознанные. Если ни в одном промежутке из группы нет хотя бы одного корректного слова, помечаем этот диапазон как не распознанный.

Таким образом получаем лучшую из возможных комбинацию результатов, в которой не распознанные участки помечены спецсимволом MASK. Если предложение не удалось распознать полностью, то фраза анализируется с помощью BERT - анализатора контекста от компании Google.

\subsection{Особенности очистки шумов}
Одной из задач, которую необходимо было решить в данной работе это предобработка звука и удаление шумов. Нам необходимо это сделать не только для уменьшения вероятности ошибки, но и для большей однородности записей.

Как мне удалось выяснить, есть два основных способа решения этой проблемы: модели на основе рекуррентных нейронных сетей, и различные алгоритмы спектрального анализа.
Мной был произведен сравнительный анализ двух инструментов, реализующих эти подходы: RNNoise и ffmpeg.

Изучив документацию по библиотеке ffmpeg я обнаружил фильтр afftdn, специально разработанный для очистки аудио от шума. В основе этого фильтра лежит алгоритм БПФ.

RNNoise — это свободный инструмент, основанный на рекуррентной нейронной сети с типом ячеек GRU. Модель RNNoise обученная на различных видах шумов, пытается анализировать аудиозапись и вычленять различные виды шума.

При практическом использовании оказалось, что фильтр afftdn справляется с задачей лучше RNNoise, и работает быстрее, поэтому для очистки шумов был выбран именно он.

\subsection{Реализация подхода}

Для реализации предложенного подхода разработана программная система, отвечающая следующим требованием:

\begin{enumerate}
\item  Возможность легкого встраивания новых процедур для обработки аудиозаписи
\item Возможность параллельного распознавания аудиозаписей с помощью ASR, следовательно необходима возможность одновременного использования одного аудио файла
\item Удобство использования и замены разных ASR использующих разные библиотеки
\item Предоставление кроссплатформенного интерфейса для работы с системой
\end{enumerate}

Для обеспечения перечисленных требований используется ансамбль докер контейнеров, задачи которым устанавливаются через REST-API сервис, который выступает интерфейсом для внешних пользователей и выполняет функцию брокера задач используя очередь задач.
В качестве конкретных инструментов для реализации были выбраны:

\begin{enumerate}
\item Язык разработки - Python3.6
\item Очередь задач - Redis
\item Сервис конвертации и очистки от шума - ffmpeg
\item Сервис диаризации - pyAudioAnalysis
\item Сервисы ASR - Kaldi, DeepSpeech, CMUSphinx
\item Система хранения файлов - Scality S3
\end{enumerate}


\subsection{Результаты}

Полученные результаты необходимо проверить по метрикам оценки качества распознавания речи и определить есть ли существенная разница между качеством распознавания ASR систем и реализованным методом.

\section{Заключение}
В работе приведен обзор методов преобразования аудиозаписей в текст. Проведен сравнительный анализ существующих реализаций для рассмотренных методов, на основе которого сделан вывод что интегральные системы пока что немного уступают в точности распознавания гибридным СММ/ИНС моделям.

Представлен интеграционный подход, который комбинирует различные ASR с системами улучшения аудио и обработкой текста.

Приведены детали реализации и проведен анализ результатов по двум метрикам качества, который показывает выигрыш используемого метода над существующими подходами.


\begin{thebibliography}{00}
\bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
\bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
\bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
\bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
\bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
\bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
\bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
\end{thebibliography}
\vspace{12pt}b

\end{document}